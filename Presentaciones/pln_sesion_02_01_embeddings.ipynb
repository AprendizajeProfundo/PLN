{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:blue\"><left>Aprendizaje Profundo</left></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"><center>Word Embedding (Incrustación de palabras)</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>$Argentina - Buenos Aires + Colombia = Bogotá$</center>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##   <span style=\"color:blue\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Asesora Medios y Marketing digital</span>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Maria del Pilar Montenegro, pmontenegro88@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Referencias</span>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Aprendizaje Profundo-Diplomado](https://github.com/AprendizajeProfundo/Diplomado)\n",
    "1. [Aprendizaje Profundo-PLN](https://github.com/AprendizajeProfundo/PLN)\n",
    "1. Varios, [Dive into deep learning](https://d2l.ai/), enero 2021\n",
    "1. Mikolov et al. 2013a, Google, [Distributed Representations of Words and Phrases\n",
    "and their Compositionality](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf), \n",
    "1. Xin Rong, 2016, [word2vec Parameter Learning Explained](https://arxiv.org/pdf/1411.2738.pdf), \n",
    "1. Mikolov et al. 2013b, Google, [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Contenido</span>\n",
    "\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [**Tokenización**](#Tokenización)\n",
    "\n",
    "- [**Word Embedding \\(Incrustación de palabras\\)**](#Word-Embedding-\\(Incrustación-de-palabras\\))\n",
    "\n",
    "- [**Métodos CBOW y Skip-gram**](#Métodos-CBOW-y-Skip-gram)\n",
    "\n",
    "- [**Modelos pre-entrenados: Word2Vec, GloVe**](#Modelos-pre-entrenados:-Word2Vec,-GloVe)\n",
    "\n",
    "- [**FastText \\(Facebook \\)**](#FastText-\\(Facebook\\))\n",
    "\n",
    "- [**Aplicaciones**](#Aplicaciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:red\"><center>Tokenización</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\"> ¿Qué significa Tokenizar? </span>\n",
    "<br></br>\n",
    "\n",
    "Tokenizar es el **proceso** de dividir textos en palabras, frases, párrafos u otros simbolos que tengan significado\n",
    "\n",
    "La unidad fundamental de la tokenización de un texto se llama **Token**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**<center>La belleza del pensamiento es su constante lucha con el Doblepensar. El resto es ceguera y sumisión.</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**Tokens (Por frase):**\n",
    "\n",
    "<center>La belleza del pensamiento es su constante lucha con el Doblepensar.</center>\n",
    "<br></br>\n",
    "<center>El resto es ceguera y sumisión.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**Tokens (Por palabras):**\n",
    "\n",
    "<center>[La, belleza, del, pensamiento, es, su, ... , y, sumisión,.]</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**Tokens (Por caracteres):**\n",
    "\n",
    "<center>[L, a, b, e, l, l, e, z, a, ... , s, i, ó, n, .]</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**Tokens (Por bi-gramas, palabras):**\n",
    "\n",
    "<center>[La belleza, belleza del, del pensamiento, ... , y sumisión, sumisión.]</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**<center>¡No es un problema fácil!</center>**\n",
    "**<center>Cada modelo tiene su propio tokenizador.</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**BERT:**\n",
    "\n",
    "<img src=\"../Imagenes/tokens_bert.png\" width=\"800\" height=\"400\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:red\"><center>Word Embedding (Incrustación de palabras)</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Problemas con los métodos clásicos de conteo</span>\n",
    "\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Baroni, Marco, Dinu Georgiana, Kruszewki Germán, (2014),[ Don’t count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors.](https://aclanthology.org/P14-1023.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "*Hipótesis distributiva*: \n",
    "\n",
    "**Palabras que ocurren y se usan en el mismo contexto, son semánticamente similares entre sí y tienen significados similares**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Ejemplo de un Embedding\n",
    "\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Frase](../Imagenes/word_embedding_matrix.png)\n",
    "\n",
    "Fuente: [Hypotheses](https://corpling.hypotheses.org/495)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "![Frase](../Imagenes/word_embedding_visual.jpg)\n",
    "\n",
    "Fuente: [Hypotheses](https://corpling.hypotheses.org/495)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**<center>¿Cómo medimos similitud entre palabras?</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "![Frase](../Imagenes/word_similarity.jpg)\n",
    "\n",
    "Fuente: [Hypotheses](https://corpling.hypotheses.org/495)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**Matemáticamente hablando,**\n",
    "\n",
    "$$\\cos(\\theta)=\\frac{\\vec{a} \\cdot \\vec{b}}{\\|\\vec{a}\\| \\| \\vec{b} \\|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:red\"><center>Métodos CBOW y Skip-gram</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">CBOW (Continuous Bag of Words)</span>\n",
    "\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se intenta **predecir la palabra objetivo actual** - target word- (la palabra central) basándose en las palabras del contexto de origen (palabras circundantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "\"A veces son las mismísimas personas de las que nadie puede imaginarse algo, aquellas que hacen las cosas que nadie puede se imaginar\".\n",
    "\n",
    "– Alan Turing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Considerando los pares (**ventana de contexto**, **palabra objetivo**), podemos construir las siguientes asociaciones (ventana de tamaño 2):\n",
    "<br></br>\n",
    "\"A veces son las mismísimas personas de las que nadie puede imaginarse algo, aquellas que hacen las cosas que nadie puede se imaginar\".\n",
    "<br></br>\n",
    "([A, son], veces)\n",
    "\n",
    "([veces, las], son)\n",
    "\n",
    "...\n",
    "\n",
    "([puede, algo], imaginarse)\n",
    "\n",
    "([aquellas, hacen], que)\n",
    "\n",
    "...\n",
    "\n",
    "Y así sucesivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**<center>Es decir, el modelo intenta predecir una palabra objetivo a partir de su contexto.</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "![cbow_1](../Imagenes/cbow_1_palabra.png)\n",
    "\n",
    "Fuente: Álvaro Montenegro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<center> Arquitectura General de CBOW</center>\n",
    "\n",
    "<center><img src=\"../Imagenes/CBOW.png\"></center>\n",
    "\n",
    "Fuente: \n",
    "[Efficient Estimation of Word Representations in Vector space](https://arxiv.org/pdf/1301.3781.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/CBOW_net_arq.png\" width=\"400\" height=\"300\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Arquitectura de la red para el modelo CBOW</p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente: \n",
    "[Dipanjan (DJ) Sarkar](https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Skip-gram</span>\n",
    "\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se intenta **predecir el contexto** - target word- (palabras circundantes) basándose en una palabra destino (palabra central)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "\"A veces son las mismísimas personas de las que nadie puede imaginarse algo, aquellas que hacen las cosas que nadie puede se imaginar\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Ejemplo:**\n",
    "\n",
    "\n",
    "(veces, [A, son])\n",
    "\n",
    "(son, [veces, las])\n",
    "\n",
    "...\n",
    "\n",
    "(imaginarse, [puede, algo])\n",
    "\n",
    "(que, [aquellas, hacen])\n",
    "\n",
    "...\n",
    "\n",
    "Y así sucesivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**<center>Es decir, el modelo intenta predecir un contexto a partir de una palabra destino.</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<center> Arquitectura General de CBOW</center>\n",
    "\n",
    "<center><img src=\"../Imagenes/SKIP_gram.png\"></center>\n",
    "\n",
    "Fuente: \n",
    "[Efficient Estimation of Word Representations in Vector space](https://arxiv.org/pdf/1301.3781.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/skip-gramar_plot.png\" width=\"400\" height=\"300\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Arquitectura de la red para el modelo CBOW</p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente: \n",
    "[Dipanjan (DJ) Sarkar](https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:red\"><center>Modelos pre-entrenados: Word2Vec, GloVe, FastText</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Word2Vec</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "![w2v](../Imagenes/word2vec.png)\n",
    "Fuente: [Training Word2vec using gensim](https://swatimeena989.medium.com/training-word2vec-using-gensim-14433890e8e4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">GloVe</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "![w2v](../Imagenes/GloVe.png)\n",
    "\n",
    "Fuente: [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:red\"><center>FastText (Facebook)</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**<center>¿Buscando Eficiencia?</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/fasttext.png\" width=\"800\" height=\"400\" align=\"center\"/>\n",
    "</figure>\n",
    "\n",
    "Fuente: [FastText](https://fasttext.cc/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9132910370826721, 'personar'),\n",
       " (0.9068970084190369, 'persona'),\n",
       " (0.8679944276809692, 'personita'),\n",
       " (0.8662665486335754, 'personal'),\n",
       " (0.8557455539703369, 'spersona'),\n",
       " (0.8324379324913025, 'persna'),\n",
       " (0.8065141439437866, 'persar'),\n",
       " (0.7967663407325745, 'personalmente'),\n",
       " (0.7958793640136719, 'personalizado'),\n",
       " (0.7871550917625427, 'persoan'),\n",
       " (0.7720642685890198, 'querer'),\n",
       " (0.7576236128807068, 'personalida'),\n",
       " (0.7519052624702454, 'perosona'),\n",
       " (0.7363068461418152, 'quere'),\n",
       " (0.7361247539520264, 'pesona'),\n",
       " (0.7349685430526733, 'debrer'),\n",
       " (0.7303863763809204, 'prematuro'),\n",
       " (0.7287424206733704, 'dde'),\n",
       " (0.726275622844696, 'caundo'),\n",
       " (0.7247213125228882, 'razòn')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.get_nearest_neighbors('personas',k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión de cada palabra: 300 \n",
      "\n",
      "[ 5.24799526e-02  9.15666297e-02  3.97484303e-02 -6.31197989e-02\n",
      "  5.07091433e-02 -4.31895442e-02  7.48612210e-02  1.57487899e-01\n",
      " -4.47557046e-04 -2.66112462e-02  7.72181004e-02 -8.77558589e-02\n",
      "  1.44190416e-01  6.08691983e-02  7.24870488e-02  1.34591535e-01\n",
      "  4.80714254e-02  1.02717467e-01 -1.65887475e-01 -7.34485462e-02\n",
      " -7.70898312e-02  3.12843353e-01 -7.42845163e-02  8.65012407e-02\n",
      "  9.27838162e-02 -1.11677237e-01  3.49321961e-01  4.53560054e-02\n",
      " -3.87068540e-02 -1.48777112e-01 -1.52624473e-01  3.16525936e-01\n",
      " -1.90377478e-02  7.65117779e-02 -4.04428989e-02  7.98542518e-03\n",
      " -2.73854584e-01 -3.61466818e-02 -2.04677321e-02  1.27188370e-01\n",
      "  2.35081464e-01 -6.66056499e-02  1.02620669e-01  7.48200193e-02\n",
      "  6.60037622e-02  1.00959092e-01 -1.76436678e-01  2.66944677e-01\n",
      " -4.28780913e-02 -2.13320721e-02 -2.34207902e-02  1.06124006e-01\n",
      "  1.96991324e-01 -9.32689980e-02  1.33505702e-01 -2.21246541e-01\n",
      " -2.66178191e-01 -8.39941278e-02 -6.15192519e-04  8.78470689e-02\n",
      "  4.23219576e-02 -1.92235291e-01  1.29888162e-01  1.07743368e-01\n",
      "  1.59951136e-01  1.60280973e-01 -4.18361574e-02 -8.61715749e-02\n",
      "  2.31133699e-01  5.71853071e-02  1.66871920e-01  1.03985675e-01\n",
      "  2.98737269e-02  1.02985054e-01  1.14707299e-01 -4.47212346e-02\n",
      " -2.22821191e-01 -1.39559433e-01 -2.11502552e-01 -4.75678556e-02\n",
      " -1.84836164e-01 -3.15176211e-02  2.65918691e-02 -1.17193414e-02\n",
      " -1.33980319e-01 -8.06756839e-02  2.40550954e-02  1.93196663e-03\n",
      " -1.52128441e-02  6.17859066e-02 -6.40573427e-02  1.33018394e-03\n",
      " -1.17561184e-01 -7.43099377e-02 -1.79671451e-01 -1.60949379e-01\n",
      " -4.95714173e-02 -1.27502605e-01 -2.99894251e-02 -1.40175223e-02\n",
      "  1.34737894e-03  4.71354797e-02  4.23890911e-02  2.79361140e-02\n",
      " -8.87208655e-02 -9.57543179e-02  1.63124248e-01  5.84070422e-02\n",
      "  6.81627728e-03 -1.30261689e-01  3.63674238e-02  9.07225609e-02\n",
      " -4.39060368e-02  9.06281993e-02 -7.72138266e-03  1.51165009e-01\n",
      "  9.62707475e-02  3.35088484e-02 -3.22040282e-02  1.37364849e-01\n",
      "  2.81820633e-02 -3.08740195e-02 -2.02313587e-02 -1.01186961e-01\n",
      "  1.72733247e-01  8.76564458e-02 -3.14652547e-02  1.41510889e-01\n",
      " -7.23000169e-02  1.32630005e-01 -1.94975939e-02 -1.00228973e-01\n",
      " -7.88610801e-02 -3.16495657e-01  2.12819017e-02 -1.71729714e-01\n",
      " -8.83882865e-02 -8.68360177e-02 -1.41904518e-01 -8.65067542e-02\n",
      " -1.76924076e-02  6.58080876e-02 -1.92414016e-01  3.47453505e-02\n",
      " -3.61692905e-03 -8.70659649e-02  7.86490962e-02  8.33094493e-03\n",
      " -3.17850232e-01 -1.51938833e-02 -6.20346330e-02 -6.64604530e-02\n",
      "  2.77439147e-01 -8.73912591e-03 -6.03523999e-02  1.90035984e-01\n",
      "  7.90233817e-03 -2.02465042e-01 -1.14850275e-01  3.99961276e-03\n",
      " -6.85938075e-02 -1.56790271e-01  1.97982341e-01 -3.46294953e-03\n",
      " -8.39912891e-02 -4.40762304e-02  9.13099349e-02 -3.56688723e-02\n",
      " -9.94093344e-02  3.76131013e-02 -1.06315218e-01  1.27028614e-01\n",
      " -6.55859560e-02 -5.92799298e-02 -2.12412834e-01  7.35279992e-02\n",
      " -6.34157956e-02 -2.28086323e-03 -2.18996704e-02 -8.67727473e-02\n",
      "  3.19884135e-03 -1.48297161e-01 -9.99149866e-03  5.26882298e-02\n",
      " -4.20790985e-02 -1.11322574e-01  4.00090218e-03  9.49732214e-02\n",
      "  1.56512000e-02  3.58194904e-03 -1.62761495e-01  3.44549976e-02\n",
      "  4.41147909e-02  3.37007828e-02  1.65453210e-01 -1.03963539e-02\n",
      "  1.36528119e-01 -1.73845127e-01  2.99894810e-02  1.95415914e-01\n",
      "  1.64505854e-01  1.58594981e-01  4.23930213e-02 -3.70294265e-02\n",
      " -9.33052972e-03 -6.29975200e-02 -3.52863148e-02  8.76879916e-02\n",
      " -9.41523910e-02  2.24974155e-02 -5.59113286e-02  1.18585072e-01\n",
      "  1.19041391e-01  1.52518570e-01  5.77507280e-02 -1.41589539e-04\n",
      " -9.08652171e-02 -7.87489191e-02 -6.25383854e-03  3.18288547e-03\n",
      "  1.00194983e-01  6.69848621e-02  1.04300432e-01  2.25197092e-01\n",
      " -1.12078451e-02 -8.93331841e-02  2.21903056e-01  1.95945892e-02\n",
      "  1.44801646e-01 -1.98350623e-01 -5.76124415e-02  1.06810912e-01\n",
      " -1.01136461e-01 -5.57082705e-02 -4.71765064e-02 -2.27710214e-02\n",
      "  4.22155336e-02  1.35813445e-01 -1.01012833e-01  5.61818406e-02\n",
      " -1.85557816e-03 -1.34610564e-01  2.09606756e-02  7.52321854e-02\n",
      "  8.02275538e-03  1.14765726e-01  6.51405007e-02 -1.52398869e-02\n",
      "  9.37117785e-02  6.09592870e-02  5.24922498e-02  2.01582052e-02\n",
      "  1.14851762e-02 -2.23667309e-01  1.46928608e-01  1.05938025e-01\n",
      "  2.06365120e-02  1.62585974e-01  1.60172984e-01  5.45519926e-02\n",
      " -5.83597943e-02  9.23366994e-02  1.07022442e-01  8.97938311e-02\n",
      "  1.30357044e-02  1.03451662e-01 -2.44069770e-02  7.09723681e-02\n",
      "  1.00608900e-01  8.87738466e-02 -3.94218117e-02  1.17261559e-01\n",
      " -4.07370590e-02  1.21892244e-01 -1.56515121e-01  2.56299204e-03\n",
      "  1.78215817e-01 -3.49422395e-02 -7.97148943e-02 -1.39361918e-01\n",
      "  1.27802566e-01  4.49165590e-02 -1.49758637e-01  1.36126921e-01\n",
      "  2.97668576e-02 -9.15807635e-02  2.06201915e-02  3.45607772e-02\n",
      "  2.01696500e-01  1.84640437e-01 -8.84667188e-02 -1.29202396e-01\n",
      "  4.75032404e-02  6.40575141e-02  6.45425245e-02  5.94188087e-03\n",
      "  1.69136554e-01 -7.58974850e-02 -5.31887449e-02 -1.04609132e-02]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensión de cada palabra:\",ft_model.dim,'\\n')\n",
    "print(ft_model.get_word_vector('persona'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:red\"><center>Aplicaciones</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/cluster_kmeans_10.png\" width=\"700\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Areas de conocimiento Astrofísica, a partir de artículos científicos</p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente: Alvaro Montenegro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.241418</td>\n",
       "      <td>-0.232559</td>\n",
       "      <td>-0.085683</td>\n",
       "      <td>0.299351</td>\n",
       "      <td>0.109705</td>\n",
       "      <td>0.331151</td>\n",
       "      <td>-0.080337</td>\n",
       "      <td>-0.197136</td>\n",
       "      <td>-0.427341</td>\n",
       "      <td>-0.573067</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225016</td>\n",
       "      <td>-0.815326</td>\n",
       "      <td>0.043260</td>\n",
       "      <td>0.105106</td>\n",
       "      <td>0.041180</td>\n",
       "      <td>0.060379</td>\n",
       "      <td>0.018453</td>\n",
       "      <td>-0.366959</td>\n",
       "      <td>0.137687</td>\n",
       "      <td>0.080184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.255045</td>\n",
       "      <td>-0.256232</td>\n",
       "      <td>-0.044591</td>\n",
       "      <td>0.315665</td>\n",
       "      <td>0.108994</td>\n",
       "      <td>0.323116</td>\n",
       "      <td>-0.106720</td>\n",
       "      <td>-0.222000</td>\n",
       "      <td>-0.435245</td>\n",
       "      <td>-0.577258</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216122</td>\n",
       "      <td>-0.807650</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.030914</td>\n",
       "      <td>0.069198</td>\n",
       "      <td>-0.006865</td>\n",
       "      <td>-0.365532</td>\n",
       "      <td>0.120305</td>\n",
       "      <td>0.078757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.239668</td>\n",
       "      <td>-0.254680</td>\n",
       "      <td>-0.070638</td>\n",
       "      <td>0.303795</td>\n",
       "      <td>0.120087</td>\n",
       "      <td>0.324071</td>\n",
       "      <td>-0.091249</td>\n",
       "      <td>-0.192964</td>\n",
       "      <td>-0.422978</td>\n",
       "      <td>-0.589075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225875</td>\n",
       "      <td>-0.816348</td>\n",
       "      <td>0.015498</td>\n",
       "      <td>0.131911</td>\n",
       "      <td>0.036075</td>\n",
       "      <td>0.064224</td>\n",
       "      <td>0.017920</td>\n",
       "      <td>-0.373993</td>\n",
       "      <td>0.126668</td>\n",
       "      <td>0.082288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.233435</td>\n",
       "      <td>-0.230949</td>\n",
       "      <td>-0.081912</td>\n",
       "      <td>0.309704</td>\n",
       "      <td>0.110778</td>\n",
       "      <td>0.327595</td>\n",
       "      <td>-0.112487</td>\n",
       "      <td>-0.204670</td>\n",
       "      <td>-0.420729</td>\n",
       "      <td>-0.566931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.222017</td>\n",
       "      <td>-0.822799</td>\n",
       "      <td>0.025876</td>\n",
       "      <td>0.108496</td>\n",
       "      <td>0.034860</td>\n",
       "      <td>0.070980</td>\n",
       "      <td>0.019631</td>\n",
       "      <td>-0.360372</td>\n",
       "      <td>0.130671</td>\n",
       "      <td>0.072055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.243229</td>\n",
       "      <td>-0.243130</td>\n",
       "      <td>-0.095961</td>\n",
       "      <td>0.292602</td>\n",
       "      <td>0.104921</td>\n",
       "      <td>0.330812</td>\n",
       "      <td>-0.077533</td>\n",
       "      <td>-0.209971</td>\n",
       "      <td>-0.430416</td>\n",
       "      <td>-0.587449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232541</td>\n",
       "      <td>-0.829176</td>\n",
       "      <td>0.029503</td>\n",
       "      <td>0.128189</td>\n",
       "      <td>0.018461</td>\n",
       "      <td>0.060638</td>\n",
       "      <td>-0.011216</td>\n",
       "      <td>-0.365519</td>\n",
       "      <td>0.143600</td>\n",
       "      <td>0.074325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7457</th>\n",
       "      <td>0.244309</td>\n",
       "      <td>-0.263245</td>\n",
       "      <td>-0.090281</td>\n",
       "      <td>0.291332</td>\n",
       "      <td>0.107840</td>\n",
       "      <td>0.307374</td>\n",
       "      <td>-0.031982</td>\n",
       "      <td>-0.228151</td>\n",
       "      <td>-0.417979</td>\n",
       "      <td>-0.612873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229120</td>\n",
       "      <td>-0.793140</td>\n",
       "      <td>0.041920</td>\n",
       "      <td>0.162498</td>\n",
       "      <td>0.015015</td>\n",
       "      <td>0.035492</td>\n",
       "      <td>-0.004617</td>\n",
       "      <td>-0.390809</td>\n",
       "      <td>0.152601</td>\n",
       "      <td>0.095524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7458</th>\n",
       "      <td>0.244283</td>\n",
       "      <td>-0.237519</td>\n",
       "      <td>-0.030111</td>\n",
       "      <td>0.291326</td>\n",
       "      <td>0.116971</td>\n",
       "      <td>0.323677</td>\n",
       "      <td>-0.053814</td>\n",
       "      <td>-0.238688</td>\n",
       "      <td>-0.426710</td>\n",
       "      <td>-0.584561</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206920</td>\n",
       "      <td>-0.785080</td>\n",
       "      <td>0.023295</td>\n",
       "      <td>0.126629</td>\n",
       "      <td>0.024351</td>\n",
       "      <td>0.071057</td>\n",
       "      <td>-0.005939</td>\n",
       "      <td>-0.393282</td>\n",
       "      <td>0.141215</td>\n",
       "      <td>0.068864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7459</th>\n",
       "      <td>0.248388</td>\n",
       "      <td>-0.247243</td>\n",
       "      <td>-0.062380</td>\n",
       "      <td>0.288513</td>\n",
       "      <td>0.108986</td>\n",
       "      <td>0.326835</td>\n",
       "      <td>-0.022564</td>\n",
       "      <td>-0.233088</td>\n",
       "      <td>-0.427388</td>\n",
       "      <td>-0.609371</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.227900</td>\n",
       "      <td>-0.821805</td>\n",
       "      <td>0.026147</td>\n",
       "      <td>0.168068</td>\n",
       "      <td>0.027383</td>\n",
       "      <td>0.020774</td>\n",
       "      <td>0.025495</td>\n",
       "      <td>-0.389975</td>\n",
       "      <td>0.142002</td>\n",
       "      <td>0.083954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7460</th>\n",
       "      <td>0.291054</td>\n",
       "      <td>-0.261208</td>\n",
       "      <td>-0.042859</td>\n",
       "      <td>0.281592</td>\n",
       "      <td>0.112613</td>\n",
       "      <td>0.312341</td>\n",
       "      <td>-0.043446</td>\n",
       "      <td>-0.256389</td>\n",
       "      <td>-0.448102</td>\n",
       "      <td>-0.611017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206487</td>\n",
       "      <td>-0.823019</td>\n",
       "      <td>-0.021799</td>\n",
       "      <td>0.135237</td>\n",
       "      <td>0.031224</td>\n",
       "      <td>0.012056</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>-0.370721</td>\n",
       "      <td>0.153655</td>\n",
       "      <td>0.102042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7461</th>\n",
       "      <td>0.238826</td>\n",
       "      <td>-0.259780</td>\n",
       "      <td>-0.079581</td>\n",
       "      <td>0.294706</td>\n",
       "      <td>0.105108</td>\n",
       "      <td>0.307628</td>\n",
       "      <td>-0.024828</td>\n",
       "      <td>-0.229253</td>\n",
       "      <td>-0.416846</td>\n",
       "      <td>-0.598813</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.235458</td>\n",
       "      <td>-0.807307</td>\n",
       "      <td>-0.000835</td>\n",
       "      <td>0.172921</td>\n",
       "      <td>0.020978</td>\n",
       "      <td>0.023366</td>\n",
       "      <td>-0.007098</td>\n",
       "      <td>-0.396306</td>\n",
       "      <td>0.137284</td>\n",
       "      <td>0.086243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7462 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0     0.241418 -0.232559 -0.085683  0.299351  0.109705  0.331151 -0.080337   \n",
       "1     0.255045 -0.256232 -0.044591  0.315665  0.108994  0.323116 -0.106720   \n",
       "2     0.239668 -0.254680 -0.070638  0.303795  0.120087  0.324071 -0.091249   \n",
       "3     0.233435 -0.230949 -0.081912  0.309704  0.110778  0.327595 -0.112487   \n",
       "4     0.243229 -0.243130 -0.095961  0.292602  0.104921  0.330812 -0.077533   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7457  0.244309 -0.263245 -0.090281  0.291332  0.107840  0.307374 -0.031982   \n",
       "7458  0.244283 -0.237519 -0.030111  0.291326  0.116971  0.323677 -0.053814   \n",
       "7459  0.248388 -0.247243 -0.062380  0.288513  0.108986  0.326835 -0.022564   \n",
       "7460  0.291054 -0.261208 -0.042859  0.281592  0.112613  0.312341 -0.043446   \n",
       "7461  0.238826 -0.259780 -0.079581  0.294706  0.105108  0.307628 -0.024828   \n",
       "\n",
       "           7         8         9    ...       290       291       292  \\\n",
       "0    -0.197136 -0.427341 -0.573067  ... -0.225016 -0.815326  0.043260   \n",
       "1    -0.222000 -0.435245 -0.577258  ... -0.216122 -0.807650  0.000162   \n",
       "2    -0.192964 -0.422978 -0.589075  ... -0.225875 -0.816348  0.015498   \n",
       "3    -0.204670 -0.420729 -0.566931  ... -0.222017 -0.822799  0.025876   \n",
       "4    -0.209971 -0.430416 -0.587449  ... -0.232541 -0.829176  0.029503   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7457 -0.228151 -0.417979 -0.612873  ... -0.229120 -0.793140  0.041920   \n",
       "7458 -0.238688 -0.426710 -0.584561  ... -0.206920 -0.785080  0.023295   \n",
       "7459 -0.233088 -0.427388 -0.609371  ... -0.227900 -0.821805  0.026147   \n",
       "7460 -0.256389 -0.448102 -0.611017  ... -0.206487 -0.823019 -0.021799   \n",
       "7461 -0.229253 -0.416846 -0.598813  ... -0.235458 -0.807307 -0.000835   \n",
       "\n",
       "           293       294       295       296       297       298       299  \n",
       "0     0.105106  0.041180  0.060379  0.018453 -0.366959  0.137687  0.080184  \n",
       "1     0.149000  0.030914  0.069198 -0.006865 -0.365532  0.120305  0.078757  \n",
       "2     0.131911  0.036075  0.064224  0.017920 -0.373993  0.126668  0.082288  \n",
       "3     0.108496  0.034860  0.070980  0.019631 -0.360372  0.130671  0.072055  \n",
       "4     0.128189  0.018461  0.060638 -0.011216 -0.365519  0.143600  0.074325  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "7457  0.162498  0.015015  0.035492 -0.004617 -0.390809  0.152601  0.095524  \n",
       "7458  0.126629  0.024351  0.071057 -0.005939 -0.393282  0.141215  0.068864  \n",
       "7459  0.168068  0.027383  0.020774  0.025495 -0.389975  0.142002  0.083954  \n",
       "7460  0.135237  0.031224  0.012056  0.009856 -0.370721  0.153655  0.102042  \n",
       "7461  0.172921  0.020978  0.023366 -0.007098 -0.396306  0.137284  0.086243  \n",
       "\n",
       "[7462 rows x 300 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<center>\n",
    "<img src=\"../Imagenes/Clustering_fasttext.png\" width=\"600\" height=\"500\" align=\"center\"/>\n",
    "</center>\n",
    "\n",
    "Fuente: Daniel Montenegro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<center>\n",
    "<img src=\"../Imagenes/sentiment_analysis.jpg\" width=\"700\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "\n",
    "Fuente: [Altexsoft](https://www.altexsoft.com/blog/business/sentiment-analysis-types-tools-and-use-cases/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
