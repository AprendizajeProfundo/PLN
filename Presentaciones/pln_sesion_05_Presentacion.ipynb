{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:blue\"><left>Aprendizaje Profundo</left></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"><center>Transformers-la Revolución</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center>All you need is attention!</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "1. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Asesora Medios y Marketing digital</span>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Maria del Pilar Montenegro, pmontenegro88@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Referencias</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Aprendizaje Profundo-Diplomado](https://github.com/AprendizajeProfundo/Diplomado)\n",
    "1. [Aprendizaje Profundo-PLN](https://github.com/AprendizajeProfundo/PLN)\n",
    "1. Ashish Vaswani et al.,  [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf), diciembre 2017.\n",
    "1. Dennis Rothman, [Transformers for Natural Language processing](http://libgen.rs/search.php?req=Transformers+for+Natural+Language+processing&open=0&res=25&view=simple&phrase=1&column=def), enero 2021.\n",
    "1. Varios,[Dive into deep learning](https://d2l.ai/), enero 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Contenido</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "* [Transformers](#Transformers)\n",
    "    * [Arquitectura original](#Arquitectura-original)\n",
    "    * [Codificación-posicional](#Codificación-posicional)\n",
    "    * [Enmascaramiento](#Enmascaramiento)\n",
    "    * [Auto-atención de producto punto escalado](#Auto-atención-de-producto-punto-escalado)\n",
    "    * [Capa de atención multi-cabeza](#Capa-de-atención-multi-cabeza)  \n",
    "    * [Capa Feed Forward](#Capa-Feed-Forward)\n",
    "    * [Transformer en acción](#Transformer-en-acción)\n",
    "    * [Capa codificadora](#Capa-codificadora)\n",
    "    * [Capa decodificadora](#Capa-decodificadora)\n",
    "    * [Codificador](#Codificador)\n",
    "    * [Decodificador](#Decodificador)\n",
    "    * [Transformer-chatbot](#Transformer-chatbot)\n",
    "    * [Transformer-traductor](#Transformer-traductor)\n",
    "  \n",
    "    \n",
    "* [BERT](#BERT)    \n",
    "     * [Introducción a BERT](#Introducción-a-BERT)\n",
    "     * [BERT-Input](#BERT-Input)\n",
    "     * [BERT-Entrenamiento Cloze task](#BERT-Entrenamiento-Cloze-task)\n",
    "     * [BERT-Entrenamiento predicción siguiente sentencia](#BERT-Entrenamiento-predicción-siguiente-sentencia)\n",
    "     * [BERT-Transferencia de conocimiento](#BERT-Transferencia-de-conocimiento)\n",
    "     * [Tokenizadores usados con Transformers](#Tokenizadores-usados-con-Transformers)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:red\"><center>Transformers</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Arquitectura original </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/Transformer_original.png\" width=\"350\" height=\"350\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Transformer</p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente: [Attention Is All You Need (Vaswani et. al, 2017)](https://arxiv.org/pdf/1706.03762.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Codificación posicional</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificación posicional discreta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 0: 0000 \n",
    "* 1: 0001\n",
    "* 2: 0010\n",
    "* 3: 0011\n",
    "* 4: 0100\n",
    "* 5: 0101\n",
    "* 6: 0110\n",
    "* 7: 0111\n",
    "* 8: 1000\n",
    "* 9: 1001\n",
    "* 10: 1010\n",
    "* 11: 1011\n",
    "* 12: 1100\n",
    "* 13: 1101\n",
    "* 14: 1110\n",
    "* 15: 1111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Codificación posicional continua en Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que $t$ es la  posición deseada en una oración de entrada y que $p_t \\in \\mathbb{R}^d$ es su correspondiente codificación. Entonces la función codificadora $f:\\mathbb{N}\\to \\mathbb{R}^d$ es definida componente a componente mediante\n",
    "\n",
    "$$\n",
    "p_t^{(i)} = f(t)^{(i)} = \\begin{cases}\n",
    "sin(w_k\\cdot t) & \\text{si i = 2k}\\\\\n",
    "cos(w_k\\cdot t) & \\text{si i = 2k+1},\n",
    "\\end{cases}\n",
    "$$\n",
    "en donde\n",
    "\n",
    "$$\n",
    "w_k = \\frac{1}{10000^{2k/d}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Enmascaramiento</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enmascaramiento de los tokens de relleno (padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se enmascaran todos los tokens de padding(relleno) en el lote de secuencia, para asegurar que el modelo no trate el relleno como entrada. Un valor de  0  en la máscara indica que esa posición en la secuencia no es relleno. Un valor de 1 en la máscara indica que esa posición en la secuencia es relleno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enmascaramiento de anticipación para la predicción de palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La máscara de anticipación se utiliza para enmascarar los tokens futuros en una secuencia. En otras palabras, la máscara indica qué entradas no deben usarse para hacer la predicción de la siguiente palabra predicha.\n",
    "\n",
    "Esto significa que para predecir la tercera palabra, solo se utilizarán la primera y la segunda palabra. De manera similar, para predecir la cuarta palabra, solo se usarán la primera, la segunda y la tercera palabra y así sucesivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Auto-atención de producto punto escalado</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/scaled_attention.png\" width=\"400\" height=\"400\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Atención de producto escalado</p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente: [Tensorflow transformer](https://www.tensorflow.org/text/tutorials/transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### La formula de auto-atención"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponemos las tres entradas Q(query o consulta), K(key o clave) y V(value o valor). La ecuación para calcular los pesos de atención es\n",
    "\n",
    "$$\n",
    "\\large \\text{Attention}(Q,K,V) = softmax\\left( \\frac{QK^T}{\\sqrt{d_k}}  \\right) V\n",
    "$$\n",
    "\n",
    "en donde  $d_k$ es el tamaño de entrada de la cabeza. En el transformer original el tamaño del embedding es 512 que se divide en 8 cabezas de tamaño $d_k=64$. Para que los tokens de relleno, usados para tener secuencias de igual tamaño, no tengan pesos de atención se les assigna un valor que tiene a $-\\infty$, de tal manera que softmax les asigne el valor cero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Capa de atención multi-cabeza</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La razón de utlizar múltiples cabezas de atención es para permitir que cada cabez se enfoque en un subconjunto del espacio de inscrustación (embedding) de los tokens. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/multi_head_attention.png\" width=\"400\" height=\"400\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Atención multi-cabeza</p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente: [Tensorflow transformer](https://www.tensorflow.org/text/tutorials/transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Capa Feed Forward</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta es la capa dense en el borde superior del Transformer, luego de la atención multicabeza y de la capa residual. Consta de dos capas completamente conectadas con una activación *ReLU* en el medio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Transformer en acción</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo Transformer sigue el mismo patrón general como un estándar `seq2seq` con atención. La sentencia  de entrada se pasa a través *N* capas de codificación (codificadoras) que generan una salida para cada palabra/símbolo en la secuencia. El decodificador presta atención a la salida del codificador y a su propia entrada (atención propia) para `predecir la siguiente palabra`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/transformer.png\" width=\"600\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Transformer</p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente: [Attention Is All You Need (Vaswani et. al, 2017)](https://arxiv.org/pdf/1706.03762.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Capa codificadora</span> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La capa codificadora corresponde al rectańgulo gris del encoder en la arquitectura del transformer arriba. Cada capa codificadora consta de subcapas:\n",
    "\n",
    "1. Atención multicabezal (con enmascaramiento de los tokens de padding)\n",
    "1. Redes densas hacia adelante (feed forward) (pointwise feed fordward).\n",
    "\n",
    "Cada una de estas subcapas tiene una conexión residual a su alrededor seguida de una normalización de capa. Las conexiones residuales ayudan a evitar el problema del desvanecimiento del gradiente en las redes profundas.\n",
    "\n",
    "La salida de cada subcapa es `LayerNorm(x + Sublayer(x))` . La normalización se realiza en el d_model eje (última). Hay N capas de codificador en el transformador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Capa decodificadora</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La capa decodificadora corresponde al rectańgulo gris del deencoder en la arquitectura del transformer arriba. Cada capa decodificadora consta de subcapas:\n",
    "\n",
    "1. Atención multi-cabeza enmascarada (con máscara de anticipación y máscara de relleno)\n",
    "2. Atención multi-cabeza (con enmascaramiento de relleno). V (valor) y K (clave) reciben la salida del codificador como entradas. Q (consulta) recibe la salida de la subcapa  multi-cabeza enmascarada.\n",
    "3. Redes densas hacia adelante (feed forward).\n",
    "\n",
    "Cada una de estas subcapas tiene una conexión residual a su alrededor seguida de una normalización de capa. La salida de cada subcapa es `LayerNorm(x + Sublayer(x))` . La normalización se realiza en el d_model eje (última).\n",
    "\n",
    "Hay *N* capas decodificadoras en el transformer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Codificador</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Encoder consta de:\n",
    "\n",
    "1. Incrustación de entrada\n",
    "1. Codificación posicional\n",
    "1. *N* capas de codificador\n",
    "\n",
    "La entrada se somete a una incrustación (embedding) que se suma con la codificación posicional. La salida de esta suma es la entrada a las capas del codificador. La salida del codificador es la entrada al decodificador.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Decodificador</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Decoder consiste en:\n",
    "\n",
    "1. Incrustación de salida\n",
    "1. Codificación posicional\n",
    "1. *N* capas de decodificador\n",
    "\n",
    "El objetivo se somete a una incrustación (embedding) que se suma con la codificación posicional. La salida de esta suma es la entrada a las capas del decodificador. La salida del decodificador es la entrada a la capa lineal final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Transformer-chatbot</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y0AqALdZCbCW"
   },
   "source": [
    "## Preparación del conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "awb4RH3XCobf"
   },
   "source": [
    "Usaremos las conversaciones en películas y programas de televisión proporcionados por [Cornell Movie-Dialogs Corpus] (https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html), que contiene más de 220 mil intercambios conversacionales. entre más de 10.000 pares de personajes de películas, como nuestro conjunto de datos.\n",
    "\n",
    "`movie_conversations.txt` contiene una lista de los ID de conversación y` movie_lines.text` contiene el texto asociado con cada ID de conversación. Para obtener más información sobre el conjunto de datos, consulte el archivo README en el archivo zip.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Preproceso de los textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    # removing contractions\n",
    "    sentence = re.sub(r\"i'm\", \"i am\", sentence)\n",
    "    sentence = re.sub(r\"he's\", \"he is\", sentence)\n",
    "    sentence = re.sub(r\"she's\", \"she is\", sentence)\n",
    "    sentence = re.sub(r\"it's\", \"it is\", sentence)\n",
    "    sentence = re.sub(r\"that's\", \"that is\", sentence)\n",
    "    sentence = re.sub(r\"what's\", \"that is\", sentence)\n",
    "    sentence = re.sub(r\"where's\", \"where is\", sentence)\n",
    "    sentence = re.sub(r\"how's\", \"how is\", sentence)\n",
    "    sentence = re.sub(r\"\\'ll\", \" will\", sentence)\n",
    "    sentence = re.sub(r\"\\'ve\", \" have\", sentence)\n",
    "    sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
    "    sentence = re.sub(r\"\\'d\", \" would\", sentence)\n",
    "    sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
    "    sentence = re.sub(r\"won't\", \"will not\", sentence)\n",
    "    sentence = re.sub(r\"can't\", \"cannot\", sentence)\n",
    "    sentence = re.sub(r\"n't\", \" not\", sentence)\n",
    "    sentence = re.sub(r\"n'\", \"ng\", sentence)\n",
    "    sentence = re.sub(r\"'bout\", \"about\", sentence)\n",
    "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "  sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Estructura del archivo 'movie_lines.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
    "\n",
    "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
    "\n",
    "L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n",
    "\n",
    "L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\n",
    "\n",
    "L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\n",
    "\n",
    "L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\n",
    "\n",
    "L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\n",
    "\n",
    "L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\n",
    "\n",
    "L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I'm kidding.  You know how sometimes you just become this \"persona\"?  And you don't know how to quit?\n",
    "\n",
    "L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Organización seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* They do not! $\\to$ They do to!\n",
    "* They do not! $\\to$ I hope so.\n",
    "* I hope so. $\\to$ She okay?\n",
    "* She okay? $\\to$ Let's go.\n",
    "* Let's go. $\\to$ Wow\n",
    "* Wow $\\to$ Okay -- you're gonna need to learn how to lie.\n",
    "* Okay -- you're gonna need to learn how to lie. $\\to$ No\n",
    "* No $\\to$ I'm kidding.  You know how sometimes you just become this \"persona\"?  And you don't know how to quit?\n",
    "* I'm kidding.  You know how sometimes you just become this \"persona\"?  And you don't know how to quit? $\\to$   Like my fear of wearing pastels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Prueba del chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "6IeMSGEgRTvC",
    "outputId": "68955e61-5c7f-4ae0-bb82-2ebfd5fdad3d"
   },
   "source": [
    "output = predict('Where have you been?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: Where have you been?\n",
    "\n",
    "Output: i am going to leave you alone ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ivVgU6ydRV8R",
    "outputId": "493ac595-e25a-4bb8-d112-45aa8d1f3169"
   },
   "source": [
    "output = predict(\"It's a trap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: It's a trap\n",
    "\n",
    "Output: you know what ? he s dead . but you can t hear that , you ll be in there till you do it ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "colab_type": "code",
    "id": "s5zG7i8KAtRU",
    "outputId": "5d2c4927-2435-4646-a2e6-27edc5ffe0a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I am not crazy, my mother had me tested.\n",
      "Output: you don t have a choice .\n",
      "\n",
      "Input: you don t have a choice .\n",
      "Output: i don t have a choice .\n",
      "\n",
      "Input: i don t have a choice .\n",
      "Output: what s wrong ?\n",
      "\n",
      "Input: what s wrong ?\n",
      "Output: you don t have to go . you don t understand\n",
      "\n",
      "Input: you don t have to go . you don t understand\n",
      "Output: i don t know . i m not sure that i do .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# feed the model with its previous output\n",
    "sentence = 'I am not crazy, my mother had me tested.'\n",
    "for _ in range(5):\n",
    "  sentence = predict(sentence)\n",
    "  print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Transformer-traductor</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usa los conjuntos de datos de TensorFlow para cargar el conjunto de datos de traducción portugués-inglés del Proyecto de traducción abierta de TED Talks.\n",
    "\n",
    "Este conjunto de datos contiene aproximadamente 50000 ejemplos de entrenamiento, 1100 ejemplos de validación y 2000 ejemplos de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Orgainzación  seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .\n",
    "1. mas e se estes fatores fossem ativos ?\n",
    "1. mas eles não tinham a curiosidade de me testar ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
    "1. but what if it were active ?\n",
    "1. but they did n't test for curiosity ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Prueba del traductor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentence = \"Eu li sobre triceratops na enciclopédia.\"\n",
    "\n",
    "ground_truth = \"I read about triceratops in the encyclopedia.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:red\"><center>BERT</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/BERT-EL-NUEVO-ALGORITMO-DE-GOOGLE.jpg\" width=\"600\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">BERT-Transformer</p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente:[Bert el nuevo algoritmo de Google](https://blog.sinapsis.agency/bert-el-nuevo-algoritmo-de-google/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Introducción a BERT</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos la implementación de HuggingFace in en Pytorch. \n",
    "\n",
    "+ BERT es un modelo con incrustaciones de posición absoluta, por lo que generalmente se recomienda rellenar (padding) las entradas a la derecha en lugar de a la izquierda.\n",
    "\n",
    "+ BERT tiene la estructura básica del codificador del transformer, con mpas cabezas, mas caps y tres embedding pocisionales que son aprendidod ene le entrenamiento.\n",
    "\n",
    "+ BERT fue entrenado con el modelado de lenguaje enmascarado (MLM) y los objetivos de predicción de la siguiente oración (NSP). Es eficiente para predecir tokens enmascarados y en NLU en general, pero no es óptimo para la generación de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">BERT-Input</span> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/BERT-Arquitectura.png\" width=\"680\" height=\"680\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">BERT-Arquitectura</p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente:[BERT: Pre-training of Deep Bidirectional Transformers for\n",
    "Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">BERT-Entrenamiento Cloze task</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/BERT-Masket.png\" width=\"500\" height=\"500\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">BERT-predicción del token enmascarado/p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente:[Finnish Language Modeling with Deep Transformer Models](https://arxiv.org/pdf/2003.11562.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">BERT-Entrenamiento predicción siguiente sentencia</span> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/BERT2sentence.jpeg\" width=\"500\" height=\"500\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">BERT-Predicción de la siguiente sentencia/p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente:[geeksforgeeks](https://www.geeksforgeeks.org/next-sentence-prediction-using-bert/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">BERT-Transferencia de conocimiento</span> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/BERT-TAREAS.jpeg\" width=\"600\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">BERT-Transferencia de conocimiento</p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente:[BERT: Pre-training of Deep Bidirectional Transformers for\n",
    "Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Tokenizadores usados con Transformers</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los tokenizadores constituyen una parte clave del entubamiento de PLN. La traea de un tokenizador es transformar un texto en datos que pueden ser procesados por el modelo.\n",
    "\n",
    "Los modelos solamente procesan números. Así que un tokenizador transforma un texto en bruto (*raw text*) en una secuencia de números."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Tokenizadores basados en palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente vamos a pensar en tokenización basada en palabras (*word-based*). La siguiente imagen ilustra le meta inicial de un toeknizador: dividir el texto bruto en palabras (o subpalabras) para encontrar una representación numérica del texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/word_based_tokenization.png\" width=\"800\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Ejemplos de tokenización por palabras</p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente: [HuggingFace Transformers course](https://huggingface.co/course/chapter2/4?fw=tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La división del texto en palabras puede hacerse directamente con la función **split** de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Daniel', 'es', 'un', 'profesor', 'de', 'inteligencia', 'artificial']\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = \" Daniel es un profesor de inteligencia artificial\".split()\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Tokenización basada en caracteres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el otro extremo se encuentran los tokenizadores basados en caracteres. En general estos generan vocabularios mucho mas cortos. En este caso aparecen problemas diferentes a los tokenizadores por palabras. A diferencia de la tokenización por  palabras en donde existen similaridades entre ellas, en la tokenizacipon por caracteres, tal similaridad se pierde. Además algunos problemas aparecen, relacionados con el manejo de la puntuación. \n",
    "\n",
    "Sinembargo esto difiere entre lso diferente lenguajes naturales. Por ejemplo en chino, cada caracter carga más información que un caracter en un  lenguaje latino. La siguiente imagen ilustra una tokenización por caracteres latinos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/character_based_tokenization.png\" width=\"800\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Ejemplos de tokenización por caracteres</p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente: [HuggingFace Transformers course](https://huggingface.co/course/chapter2/4?fw=tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Tokenización basada en subpalabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este tipo de tokenizadores se toma lo mejor de los dos mundos anteriores. La tokenización basada en subpalabras descanasa en el principio de que *palabras frecuentemente usadas no deben subdivisirse más, pero palabras menos frecuentes pueden eventualmente ser subdivididas en subpalabras cons siginficado. Dos ejemplos de tokenización basados en subpalabras son los siguientes.\n",
    "\n",
    "1. Las palabras *perro* y *perros* son diferentes. Pero es claro que se refieren a lo mismo. Si se codifican separadamente con ID's distintos, esta similaridad natural se pierde. Una solución que puede adoptrase es por ejemplo codificar las palabras 'perro' y 's'. por separado. Un tokenizador entrenado de esta forma haría la tokenización d elas dos palabras de la siguiente forma:\n",
    "    * 'perro' -> {'perro'} -> {{35}}\n",
    "    * 'perros' -> {'perro', 's'} -> {{35}, {60}}\n",
    "    * 'casa' -> {'casa'} -> {{85}}\n",
    "    * 'casas' -> {'casa', 's'} -> {{85}, {60}}\n",
    "    \n",
    "Observe que 'perros' y 'casas' comparten el hecho de ser palabras plurales.\n",
    "\n",
    "2. Las palabras *bailar*, *bailamos*, *bailaríamos*, *bailaremos* se tokenizarían como\n",
    "    * 'bailar* -> {'baila', 'r'} -> {{110},{59}}\n",
    "    * 'bailamos* -> {'baila', 'mos'} -> {{110},{90}}\n",
    "    * 'bailaríamos* -> {'baila', 'ríamos'} -> {{110},{95}}\n",
    "    * 'bailaremos* -> {'baila', 'remos'} -> {{110},{98}}\n",
    "    \n",
    "Asi, sucesivamente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Tokenización basada en otros enfoques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Existen muchas más técnicas. Por ejemplo:\n",
    "\n",
    "1. Byte-level, usado en [GPT-2](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)\n",
    "1. WordPiece, usado en [BERT](https://arxiv.org/pdf/1810.04805.pdf)\n",
    "1. SentencePiece o Unigram, usado en varios modelos multilingua."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/word_based_tokenization.png\" width=\"600\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">BERT-word-piece tokenizer</p>\n",
    "</figcaption>\n",
    "</figure>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
